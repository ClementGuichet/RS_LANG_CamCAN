##########################################################################################
# Script for aggregating binary graph measures per subject per threshold for LANG 131 ROIs
# For details regarding the 131 ROIs, see Roger et al. (2022). Unraveling the functional attributes of the language connectome

# Written by CG - 2023

##########################################################################################
library(pacman)
pacman::p_load("tidyverse", "janitor", "readr", "readxl", "car", "Rmisc", "Hmisc", "tidylog",
               "ggpubr", "data.table", "rstatix")

rm(list = ls())

data_wrangling <- function(n_subj, n_threshold, filtering_scheme = NULL) {
  ##########################################################################################
  ##########################################################################################
  # Import network labeling generated by InLang & by our network overlap calculator --------
  ##########################################################################################
  ##########################################################################################
  
  Network_overlap_InLang <- read_excel("Network_overlap_InLang.xlsx",
                                       sheet = "Liberal"
  ) %>%
    janitor::row_to_names(1)
  
  # Import Consensus community vectors
  Consensus_vector <- read_excel("Consensus_vectors_CamCAN.xlsx") %>%
    mutate_at(vars(starts_with("Consensus")), funs(as.character(as.numeric(.))))
  
  meta_data_0 <- merge(Network_overlap_InLang, Consensus_vector, by = "Region")
  
  # Import meta-data on participants
  meta_data_1 <- read_excel("meta_data_628/participant_data_T1.xlsx")[, 1:8] %>% 
    dplyr::select(-c("gender_code", "hand")) %>%
    rename(Subj_ID = Subject) %>% 
    rename(Age = age) %>% 
    replace("Subj_ID", seq_len(628)) %>%
    mutate(Gender_c = ifelse(gender_text == "MALE", -0.5, 0.5))

  ##########################################################################################
  ##########################################################################################
  # Import data -------------------------------------
  ##########################################################################################
  ##########################################################################################
  
  if (filtering_scheme == "OMST") {
    setwd(paste0(getwd(), "/OMST"))
  # List all txt files & extract the files
  listfile <- list.files(getwd(), pattern = "*.txt")
  
  # Local Metrics-------------------------------------
  
  # Degree centrality-------------------------------
  listfile_degree <- listfile[grep("degrees", listfile)]
  
  degree <<- ldply(listfile_degree, read.table, header = T, sep = "\t") %>% 
    mutate(threshold = rep("OMST")) %>%
    # mutate(threshold = rep(c(.1, .12, .15, .17, .2), each = n_subj)) %>%
    relocate(threshold, .after = (X)) %>%
    rename(Subj_ID = X) %>% 
    replace("Subj_ID", rep(seq_len(n_subj))) %>%
    # replace("Subj_ID", rep(seq_len(n_subj), times = n_threshold)) %>%
    pivot_longer(
      cols = !c("Subj_ID", "threshold"),
      names_to = "Region",
      values_to = "degree"
    )
  
  # Betweenness centrality-------------------------
  listfile_BC <- listfile[grep("betweenness", listfile)]
  
  BC <<- ldply(listfile_BC, read.table, header = T, sep = "\t") %>%
    mutate(threshold = rep("OMST")) %>%
    # mutate(threshold = rep(c(.1, .12, .15, .17, .2), each = n_subj)) %>%
    relocate(threshold, .after = (X)) %>%
    rename(Subj_ID = X) %>% 
    replace("Subj_ID", rep(seq_len(n_subj))) %>% 
    # replace("Subj_ID", rep(seq_len(n_subj), times = n_threshold)) %>%
    pivot_longer(
      cols = !c("Subj_ID", "threshold"),
      names_to = "Region",
      values_to = "Betweenness"
    ) 
    # mutate(Betweenness = Betweenness/((131-1)*(131-2)))
  
  # Flow centrality-------------------------------
  listfile_flow <- listfile[grep("flow", listfile)]
  
  Flow <<- ldply(listfile_flow, read.table, header = T, sep = "\t") %>%
    mutate(threshold = rep("OMST")) %>%
    # mutate(threshold = rep(c(.1, .12, .15, .17, .2), each = n_subj)) %>%
    relocate(threshold, .after = (X)) %>%
    rename(Subj_ID = X) %>% 
    replace("Subj_ID", rep(seq_len(n_subj))) %>% 
    # replace("Subj_ID", rep(seq_len(n_subj), times = n_threshold)) %>%
    pivot_longer(
      cols = !c("Subj_ID", "threshold"),
      names_to = "Region",
      values_to = "Flow_coeff"
    )
  
  
  # Local efficiency-------------------------------
  listfile_Eloc <- listfile[grep("efficiency_local", listfile)]
  
  Eloc <<- ldply(listfile_Eloc, read.table, header = T, sep = "\t") %>%
    mutate(threshold = rep("OMST")) %>%
    # mutate(threshold = rep(c(.1, .12, .15, .17, .2), each = n_subj)) %>%
    relocate(threshold, .after = (X)) %>%
    rename(Subj_ID = X) %>% 
    replace("Subj_ID", rep(seq_len(n_subj))) %>% 
    # replace("Subj_ID", rep(seq_len(n_subj), times = n_threshold)) %>%
    pivot_longer(
      cols = !c("Subj_ID", "threshold"),
      names_to = "Region",
      values_to = "Eloc"
    )
  
  
  
  # Global Metrics------------------------------------
  # Global efficiency & Clustering coefficient global-------------------------
  listfile_Glob <- listfile[grep("global", listfile)]
  
  Glob_final <<- ldply(listfile_Glob, read.table, header = T, sep = "\t") %>%
    mutate(threshold = rep("OMST")) %>%
    # mutate(threshold = rep(c(.1, .12, .15, .17, .2), each = n_subj)) %>%
    relocate(threshold, .after = (X)) %>%
    rename(Subj_ID = X) %>% 
    rename(Eglob = efficiency_bin) %>% 
    rename(Clustering_coeff_glob = clusterMean_bu) %>% 
    # rename(Cost_efficiency = cost_efficiency_relative_bin) %>% 
    # plyr::rename(c("modularity_louvain_QOut_und" = "Modularity_Q")) %>%
    replace("Subj_ID", rep(seq_len(n_subj))) %>% 
    # replace("Subj_ID", rep(seq_len(n_subj), times = n_threshold)) %>%
    dplyr::select(Subj_ID, threshold, Eglob, Clustering_coeff_glob)
  
  # Add the Modularity Q for each threshold from the consensus-based community detection
  # See in path/to/GraphVar/RS_CamCAN_LANG131/results/Consensus_clustering
  # Q_consensus <- c(.4699, .4601, .4580, .4620, .4582)
  # threshold <- c(.1, .12, .15, .17, .2)
  # output <- cbind(threshold, Q_consensus)
  
  # Glob_final <<- merge(Glob, output, by.x = "threshold", all = T)
  setwd(str_replace(getwd(), "\\/OMST", ""))
  
  } else if (filtering_scheme == "proportional") {
    setwd(paste0(getwd(), "/data_graphvar_T1"))
    # List all txt files & extract the files
    listfile <- list.files(getwd(), pattern = "*.txt")
    
    # Local Metrics-------------------------------------
    
    # Degree centrality-------------------------------
    listfile_degree <- listfile[grep("degrees", listfile)]
    
    degree <- ldply(listfile_degree, read.table, header = T, sep = "\t") %>% 
      mutate(threshold = rep(c(.1, .12, .15, .17, .2), each = n_subj)) %>%
      relocate(threshold, .after = (X)) %>%
      rename(Subj_ID = X) %>% 
      replace("Subj_ID", rep(seq_len(n_subj), times = n_threshold)) %>%
      pivot_longer(
        cols = !c("Subj_ID", "threshold"),
        names_to = "Region",
        values_to = "degree"
      )
    
    # Betweenness centrality-------------------------
    listfile_BC <- listfile[grep("betweenness", listfile)]

    BC <<- ldply(listfile_BC, read.table, header = T, sep = "\t") %>%
      mutate(threshold = rep(c(.1, .12, .15, .17, .2), each = n_subj)) %>%
      relocate(threshold, .after = (X)) %>%
      rename(Subj_ID = X) %>%
      replace("Subj_ID", rep(seq_len(n_subj), times = n_threshold)) %>%
      pivot_longer(
        cols = !c("Subj_ID", "threshold"),
        names_to = "Region",
        values_to = "Betweenness"
      )
    # mutate(Betweenness = Betweenness/((131-1)*(131-2)))

    
    # Flow centrality-------------------------------
    listfile_flow <- listfile[grep("flow", listfile)]
    
    Flow <<- ldply(listfile_flow, read.table, header = T, sep = "\t") %>%
      mutate(threshold = rep(c(.1, .12, .15, .17, .2), each = n_subj)) %>%
      relocate(threshold, .after = (X)) %>%
      rename(Subj_ID = X) %>% 
      replace("Subj_ID", rep(seq_len(n_subj), times = n_threshold)) %>%
      pivot_longer(
        cols = !c("Subj_ID", "threshold"),
        names_to = "Region",
        values_to = "Flow_coeff"
      )
    
    
    # Local efficiency-------------------------------
    listfile_Eloc <- listfile[grep("efficiency_local", listfile)]
    
    Eloc <<- ldply(listfile_Eloc, read.table, header = T, sep = "\t") %>%
       mutate(threshold = rep(c(.1, .12, .15, .17, .2), each = n_subj)) %>%
      relocate(threshold, .after = (X)) %>%
      rename(Subj_ID = X) %>% 
      replace("Subj_ID", rep(seq_len(n_subj), times = n_threshold)) %>%
      pivot_longer(
        cols = !c("Subj_ID", "threshold"),
        names_to = "Region",
        values_to = "Eloc"
      )
    
    
    
    # Global Metrics------------------------------------
    # Global efficiency & Clustering coefficient global-------------------------
    listfile_Glob <- listfile[grep("global", listfile)]
    
    Glob_final <<- ldply(listfile_Glob, read.table, header = T, sep = "\t") %>%
      mutate(threshold = rep(c(.1, .12, .15, .17, .2), each = n_subj)) %>%
      relocate(threshold, .after = (X)) %>%
      rename(Subj_ID = X) %>% 
      rename(Eglob = efficiency_bin) %>% 
      rename(Clustering_coeff_glob = clusterMean_bu) %>% 
      # rename(Cost_efficiency = cost_efficiency_relative_bin) %>% 
      # plyr::rename(c("modularity_louvain_QOut_und" = "Modularity_Q")) %>%
      replace("Subj_ID", rep(seq_len(n_subj), times = n_threshold)) %>%
      dplyr::select(Subj_ID, threshold, Eglob, Clustering_coeff_glob)
    
    # Add the Modularity Q for each threshold from the consensus-based community detection
    # See in path/to/GraphVar/RS_CamCAN_LANG131/results/Consensus_clustering
    # Q_consensus <- c(.4699, .4601, .4580, .4620, .4582)
    # threshold <- c(.1, .12, .15, .17, .2)
    # output <- cbind(threshold, Q_consensus)
    
    # Glob_final <<- merge(Glob, output, by.x = "threshold", all = T)
    
    # Removing subjects with less than 90% of connected regions
    listfile_components <- list.files(getwd(), pattern = "*.txt")[grep("components", list.files(getwd(), pattern = "*.txt"))]
  
    components <- ldply(listfile_components, read.table, header = T, sep = "\t") %>%
      # mutate(threshold = rep("OMST")) %>% 
      mutate(threshold = rep(c(.1, .12, .15, .17, .2), each = n_subj)) %>%
      relocate(threshold, .after = (X)) %>%
      plyr::rename(c("X" = "Subj_ID")) %>%
      # replace("Subj_ID", rep(seq_len(n_subj))) %>%
      replace("Subj_ID", rep(seq_len(n_subj), times = n_threshold)) %>%
      pivot_longer(
        cols = !c("Subj_ID", "threshold"),
        names_to = "Region",
        values_to = "components"
      )
    
    # # Get proportion of LLC per threshold across subjects
    LLC_filter <<- components %>%
      group_by(Subj_ID) %>%
      count(threshold, components) %>%
      group_by(Subj_ID, threshold) %>%
      mutate(prop = prop.table(n)) %>%
      slice_max(prop, n = 1) %>% 
      filter(threshold == "0.15") %>% 
      filter(prop > 0.9)
    
    LLC_threshold <<- components %>%
      group_by(Subj_ID) %>%
      count(threshold, components) %>%
      group_by(Subj_ID, threshold) %>%
      mutate(prop = prop.table(n)) %>%
      slice_max(prop, n = 1) %>% 
      group_by(threshold) %>%
      summarise_at(vars(prop), mean) %>%
      plyr::rename(c("prop" = "Largest Connected Component"))
  
    setwd(str_replace(getwd(), "\\/data_graphvar_T1", ""))
  
  }
  
  ################################################################################
  ################################################################################
  # Merge all data
  ################################################################################
  ################################################################################
  
  # For local metrics
  tmp_local_0 <- cbind(
    degree,
    Betweenness = BC$Betweenness,
    Flow_coeff = Flow$Flow_coeff,
    Eloc = Eloc$Eloc
  )
  
  # Add subject information to local metrics
  tmp_local_1 <- merge(meta_data_1, tmp_local_0, by = "Subj_ID")
  
  # Add RSNs classification, consensus vectors & global metrics
  # DIMENSIONS 645 Subjects * 131 Regions * 5 thresholds
  data_full <<- merge(tmp_local_1, meta_data_0, by = "Region") %>%
    relocate(Region, .after = Subj_ID) %>%
    relocate(Index.Power264, .before = Region) %>%
    arrange(Subj_ID, Region, threshold) %>%
    merge(., Glob_final %>%
            dplyr::select(Subj_ID, threshold, Eglob, Clustering_coeff_glob),
          by = c("Subj_ID", "threshold")
    ) %>%
    arrange(Subj_ID, threshold, Region) %>%
    mutate_at(vars(Age), funs(as.numeric(.)))

  
  # Combining data for each row = one subject
  data_local_per_subject <- data_full %>%
    group_by(Subj_ID, threshold) %>%
    summarize_at(vars(degree:Eloc), mean)
  
  data_global_per_subject <- merge(meta_data_1, Glob_final, by = "Subj_ID") %>%
    arrange(Subj_ID, threshold)
  
  # DIMENSIONS 628 Subjects * 5 thresholds
  data_full_per_subject <<- merge(data_global_per_subject, data_local_per_subject, by = c("Subj_ID", "threshold")) %>%
    arrange(Subj_ID, threshold)
  
  # Combining data for each row = one region
  data_local_per_region <- data_full %>% 
    group_by(Region, threshold) %>%
    summarize_at(vars(degree:Eloc), mean)
  
  data_global_per_region <- merge(data_local_per_region, Glob_final %>%
                                    group_by(threshold) %>%
                                    summarize_at(vars(Eglob:Clustering_coeff_glob), mean), by = "threshold")
  
  # DIMENSIONS 131 Regions * 5 thresholds
  data_full_per_region <<- merge(data_global_per_region, meta_data_0, by = "Region")
}

data_wrangling(628, 5, "proportional")


################################################################################
# Output-------------------------------
################################################################################

rm(list = ls()[!ls() %in% c("data_full", "data_full_per_subject", "data_full_per_region",  "LLC_filter", "LLC_threshold")])


##########################################################################################
# Script for aggregating binary graph measures per subject per threshold for LANG 131 ROIs
# For details regarding the 131 ROIs, see Roger et al. (2022). Unraveling the functional attributes of the language connectome

# Written by CG
# 21-11-2022

##########################################################################################
library(pacman)
pacman::p_load("tidyverse", "janitor", "readr", "readxl", "car", "Rmisc", "Hmisc", "tidylog",
               "ggpubr", "data.table", "rstatix")

rm(list = ls())

##########################################################################################
##########################################################################################
# Import network labeling generated by InLang & by our network overlap calculator --------
##########################################################################################
##########################################################################################

Network_overlap_InLang <- read_excel("Network_overlap_InLang.xlsx",
  sheet = "Liberal"
) %>%
  janitor::row_to_names(1)

# Import Consensus community vectors
Consensus_vector <- read_excel("Consensus_vectors_CamCAN.xlsx") %>%
  mutate_at(vars(starts_with("Consensus")), funs(as.character(as.numeric(.))))

meta_data_0 <- merge(Network_overlap_InLang, Consensus_vector, by = "Region")

# Import meta-data on participants
meta_data_1 <- read_excel("meta_data_628/participant_data_T1.xlsx")[, 1:8] %>% 
  dplyr::select(-c("gender_code", "hand")) %>%
  rename(Subj_ID = Subject) %>% 
  rename(Age = age) %>% 
  replace("Subj_ID", seq_len(628)) %>%
  mutate(Gender_c = ifelse(gender_text == "MALE", -0.5, 0.5))

# CAMCAN_cognitive_data <- read_excel("meta_data_628/CognitiveData_CamCAN_Apr2022.xlsx") %>%
#   filter(Observations %in% participant_data$Observations) %>%
#   dplyr::select(-gender_code) %>%
#   rename(Age_CogData = Age)

# meta_data_1 <- merge(participant_data, CAMCAN_cognitive_data, by = "Observations")

##########################################################################################
##########################################################################################
# Import data -------------------------------------
##########################################################################################
##########################################################################################
data_wrangling <- function(n_subj, n_threshold) {
  setwd(paste0(getwd(), "/OMST"))
  # List all txt files & extract the files
  listfile <- list.files(getwd(), pattern = "*.txt")
  
  # Local Metrics-------------------------------------
  
  # Degree centrality-------------------------------
  listfile_degree <- listfile[grep("degrees", listfile)]
  
  degree <<- ldply(listfile_degree, read.table, header = T, sep = "\t") %>% 
    mutate(threshold = rep("OMST")) %>%
    # mutate(threshold = rep(c(.1, .12, .15, .17, .2), each = n_subj)) %>%
    relocate(threshold, .after = (X)) %>%
    rename(Subj_ID = X) %>% 
    replace("Subj_ID", rep(seq_len(n_subj))) %>%
    # replace("Subj_ID", rep(seq_len(n_subj), times = n_threshold)) %>%
    pivot_longer(
      cols = !c("Subj_ID", "threshold"),
      names_to = "Region",
      values_to = "degree"
    )
  
  # Betweenness centrality-------------------------
  listfile_BC <- listfile[grep("betweenness", listfile)]
  
  BC <<- ldply(listfile_BC, read.table, header = T, sep = "\t") %>%
    mutate(threshold = rep("OMST")) %>%
    # mutate(threshold = rep(c(.1, .12, .15, .17, .2), each = n_subj)) %>%
    relocate(threshold, .after = (X)) %>%
    rename(Subj_ID = X) %>% 
    replace("Subj_ID", rep(seq_len(n_subj))) %>% 
    # replace("Subj_ID", rep(seq_len(n_subj), times = n_threshold)) %>%
    pivot_longer(
      cols = !c("Subj_ID", "threshold"),
      names_to = "Region",
      values_to = "Betweenness"
    ) 
    # mutate(Betweenness = Betweenness/((131-1)*(131-2)))
  
  # Flow centrality-------------------------------
  listfile_flow <- listfile[grep("flow", listfile)]
  
  Flow <<- ldply(listfile_flow, read.table, header = T, sep = "\t") %>%
    mutate(threshold = rep("OMST")) %>%
    # mutate(threshold = rep(c(.1, .12, .15, .17, .2), each = n_subj)) %>%
    relocate(threshold, .after = (X)) %>%
    rename(Subj_ID = X) %>% 
    replace("Subj_ID", rep(seq_len(n_subj))) %>% 
    # replace("Subj_ID", rep(seq_len(n_subj), times = n_threshold)) %>%
    pivot_longer(
      cols = !c("Subj_ID", "threshold"),
      names_to = "Region",
      values_to = "Flow_coeff"
    )
  
  
  # Local efficiency-------------------------------
  listfile_Eloc <- listfile[grep("efficiency_local", listfile)]
  
  Eloc <<- ldply(listfile_Eloc, read.table, header = T, sep = "\t") %>%
    mutate(threshold = rep("OMST")) %>%
    # mutate(threshold = rep(c(.1, .12, .15, .17, .2), each = n_subj)) %>%
    relocate(threshold, .after = (X)) %>%
    rename(Subj_ID = X) %>% 
    replace("Subj_ID", rep(seq_len(n_subj))) %>% 
    # replace("Subj_ID", rep(seq_len(n_subj), times = n_threshold)) %>%
    pivot_longer(
      cols = !c("Subj_ID", "threshold"),
      names_to = "Region",
      values_to = "Eloc"
    )
  
  
  
  # Global Metrics------------------------------------
  # Global efficiency & Clustering coefficient global-------------------------
  listfile_Glob <- listfile[grep("global", listfile)]
  
  Glob_final <<- ldply(listfile_Glob, read.table, header = T, sep = "\t") %>%
    mutate(threshold = rep("OMST")) %>%
    # mutate(threshold = rep(c(.1, .12, .15, .17, .2), each = n_subj)) %>%
    relocate(threshold, .after = (X)) %>%
    rename(Subj_ID = X) %>% 
    rename(Eglob = efficiency_bin) %>% 
    rename(Clustering_coeff_glob = clusterMean_bu) %>% 
    # rename(Cost_efficiency = cost_efficiency_relative_bin) %>% 
    # plyr::rename(c("modularity_louvain_QOut_und" = "Modularity_Q")) %>%
    replace("Subj_ID", rep(seq_len(n_subj))) %>% 
    # replace("Subj_ID", rep(seq_len(n_subj), times = n_threshold)) %>%
    dplyr::select(Subj_ID, threshold, Eglob, Clustering_coeff_glob)
  
  # Add the Modularity Q for each threshold from the consensus-based community detection
  # See in path/to/GraphVar/RS_CamCAN_LANG131/results/Consensus_clustering
  # Q_consensus <- c(.4699, .4601, .4580, .4620, .4582)
  # threshold <- c(.1, .12, .15, .17, .2)
  # output <- cbind(threshold, Q_consensus)
  
  # Glob_final <<- merge(Glob, output, by.x = "threshold", all = T)
  setwd(str_replace(getwd(), "\\/OMST", ""))
}
data_wrangling(628, 5)


################################################################################
################################################################################
# Merge all data
################################################################################
################################################################################

# For local metrics
tmp_local_0 <- cbind(
  degree,
  Betweenness = BC$Betweenness,
  Flow_coeff = Flow$Flow_coeff,
  Eloc = Eloc$Eloc
)

# Add subject information to local metrics
tmp_local_1 <- merge(meta_data_1, tmp_local_0, by = "Subj_ID")

# Add RSNs classification, consensus vectors & global metrics
# DIMENSIONS 645 Subjects * 131 Regions * 5 thresholds

data_full <- merge(tmp_local_1, meta_data_0, by = "Region") %>%
  relocate(Region, .after = Subj_ID) %>%
  relocate(Index.Power264, .before = Region) %>%
  arrange(Subj_ID, Region, threshold) %>%
  merge(., Glob_final %>%
    dplyr::select(Subj_ID, threshold, Eglob, Clustering_coeff_glob),
  by = c("Subj_ID", "threshold")
  ) %>%
  arrange(Subj_ID, threshold, Region) %>%
  mutate_at(vars(Age), funs(as.numeric(.)))

# Combining data for each row = one subject
data_local_per_subject <- data_full %>%
  group_by(Subj_ID, threshold) %>%
  summarize_at(vars(degree:Eloc), mean)

data_global_per_subject <- merge(meta_data_1, Glob_final, by = "Subj_ID") %>%
  arrange(Subj_ID, threshold)

# DIMENSIONS 628 Subjects * 5 thresholds
data_full_per_subject <- merge(data_global_per_subject, data_local_per_subject, by = c("Subj_ID", "threshold")) %>%
  arrange(Subj_ID, threshold)

# Combining data for each row = one region
data_local_per_region <- data_full %>% 
  group_by(Region, threshold) %>%
  summarize_at(vars(degree:Eloc), mean)

data_global_per_region <- merge(data_local_per_region, Glob_final %>%
  group_by(threshold) %>%
  summarize_at(vars(Eglob:Clustering_coeff_glob), mean), by = "threshold")

# DIMENSIONS 131 Regions * 5 thresholds
data_full_per_region <- merge(data_global_per_region, meta_data_0, by = "Region")
################################################################################
# Output-------------------------------
rm(list = ls()[!ls() %in% c("data_full", "data_full_per_subject", "data_full_per_region")])

